# Group-9:Outlier Detection of User behavior on Yelp Data
<h3>Authors</h3>
Jie Dong</br>
Enze Wu</br>
Lei Sun

<h3>Description</h3>

Reviews in Yelp play important role in making purchase decisions and help people to narrow down the options and to make decision based on their needs. And from business point of view, positive reviews can result in significant financial benefits. But this also provides opportunities for deceptions, where fake reviews can be generated to garner positive opinions about a product or to disrepute some businesses. Our project is to explore datasets given by Yelp and to better understand user behaviors in Yelp and find out the outliers which might be fakes, advertisements or spams given by robot. Even if finally we can not explicitly give the definition of ‘fake review’ or distinguish all the ‘fake reviews’ types from the normal reviews. By studying user behavior we can help Yelp to better understand about their users, help customers know the reviews written by whom are untrustable, and help business owners to better understand how they are being evaluated and maybe create actions to improve their ratings in Yelp.

<h3>Screenshot of our application</h3>
![image](https://github.com/sunscorch/screemshot/blob/master/Screen%20Shot%202015-12-19%20at%2011.59.11%20PM.png)
<h3>The Data</h3>

All the data is provided by Yelp in terms of json file format. It includs business, checkin, review, user, tip datasets. We use database to get 12 features of each user and put them into a csv file for further processing.</br>
[Data link](https://github.com/nyu-cs6313-fall2015/Group-9/blob/master/sample1.csv)


<h3>Live Demo</h3>
[Link to our application](http://nyu-cs6313-fall2015.github.io/Group-9/index)


<h3>Final Proposal</h3>
[Link to Final Proposal](https://github.com/nyu-cs6313-fall2015/Group-9/blob/master/report/Outlier%20Detection%20of%20User%20behavior%20on%20Yelp%20Data.pdf)

<h3>Video</h3>
[Link to video](https://vimeo.com/149665108)

